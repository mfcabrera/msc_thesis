{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluating the Results from Word2Vec vs the result"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We import word2vec to make it cool"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import word2vec \n",
      "import os\n",
      "import pprint as pp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We load a previously created thing, seeing if this implementation work. This is a huge file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec_file = '../../gini_thesis/experiments/dewiki-full-nostemm-DE0011.bin'\n",
      "print \"File size: %iGB\" %  (os.path.getsize(vec_file) / (1024.0 * 1024 * 1024))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File size: 2GB\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = word2vec.load(vec_file,True,True) # Binary format and save memory ... curioous\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's test first the existence of some words\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.cosine('beste')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "{'beste': [('bester', 0.80862715211137748),\n",
        "  ('bestes', 0.78943320248449433),\n",
        "  ('nebendarstellerin', 0.75782492147869929),\n",
        "  ('nominierung', 0.75595610309258698),\n",
        "  ('newcomerin', 0.75250601981011456),\n",
        "  ('nominierungen', 0.74955782266301774),\n",
        "  ('besten', 0.74561018058208761),\n",
        "  ('nominiert', 0.74412707212303697),\n",
        "  ('nachwuchsdarstellerin', 0.74389365816426301),\n",
        "  ('hauptdarstellerin', 0.73982425496171822)]}"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Evaluating the Currency"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's evaluate the currency with the loaded model in memory and investigate what is going on here.  For our best model this taks gives and accuracy of **7.74% (67/866)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Algerien dinar Angola kwanza\n",
      "# Bulgarien lev Indien rupee\n",
      "# Japan yen Korea won\n",
      "\n",
      "# vec[1] - vec[0] + vec[2] = vec[3]\n",
      "pp.pprint(model.analogy(pos=['dinar', 'angola'], neg=['algerien'], n=5))\n",
      "pp.pprint(model.analogy(pos=['lev', 'indien'], neg=['bulgarien'], n=5))\n",
      "pp.pprint(model.analogy(pos=['yen', 'japan'], neg=['japan'], n=5))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('waehrung', 0.26670958774859621),\n",
        " ('centavos', 0.26550662258084379),\n",
        " ('escudos', 0.26365943429271949),\n",
        " ('pataca', 0.26343558421229618),\n",
        " ('kwacha', 0.26046197935244575),\n",
        " ('peso', 0.25645094676679669)]\n",
        "["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('indische', 0.23986818745749885),\n",
        " ('bombay', 0.23653432994435442),\n",
        " ('indiens', 0.23071699582049873),\n",
        " ('indischen', 0.23042548434135146),\n",
        " ('vidya', 0.23029838546832565)]\n",
        "["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('qapla', 0.2239875867478148),\n",
        " ('jpy', 0.21131588917635691),\n",
        " ('renminbi', 0.20532152883265559),\n",
        " ('hongkonger', 0.19222247034714302),\n",
        " ('zotto', 0.19141076198761126),\n",
        " ('kancho', 0.19045534946169024)]\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This results displays that some of them work and some of them although grammatically correct the word is not exactly the expected (Korea vs Sudkorea) or  is the first postions. Of course there are other cases in which nonen of the vectors matched represent a somewhat logical relationships. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Superlative"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "let's see how the superlative work. We obtained with our best model ** 3.82 %  (31 / 812) **-\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#vec = ['schlecht','schlechter', 'gross', 'groesster']\n",
      "vec = ['schlecht', 'schlechtesten', 'gross', 'groessten']\n",
      "\n",
      "vec2 =  ['hell','hellste', 'kalt', 'kaelteste']\n",
      "vec3 = ['dunkel', 'dunkelsten', 'zuegig', 'zuegigsten']\n",
      "# vec[1] - vec[0] + vec[2] = vec[3]\n",
      "\n",
      "pp.pprint(model.analogy(pos=[vec[1], vec[2]], neg=[vec[0]], n=5))\n",
      "pp.pprint(model.analogy(pos=[vec2[1], vec2[2]], neg=[vec2[0]], n=5))\n",
      "pp.pprint(model.analogy(pos=[vec3[1], vec3[2]], neg=[vec3[0]], n=5))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('jarecki', 0.19192581220951574),\n",
        " ('hauptpreises', 0.19117812725008182),\n",
        " ('darstellerkategorien', 0.18669328620462433),\n",
        " ('youngstar', 0.18636425744656265),\n",
        " ('mvps', 0.18499659099860521)]\n",
        "["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('himmelsaequators', 0.28295985712097704),\n",
        " ('sternsystem', 0.28235337482013673),\n",
        " ('freiaeugig', 0.28205529857555023),\n",
        " ('zentralgestirn', 0.27995720618611764),\n",
        " ('schlangentraeger', 0.27897589233254705)]\n",
        "["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('bemessene', 0.26732466949442452),\n",
        " ('volkstaat', 0.26683555987010343),\n",
        " ('enormem', 0.26663330688284387),\n",
        " ('rueckende', 0.2649556549646136),\n",
        " ('unuebersehbares', 0.26431468032856203),\n",
        " ('zoegerlicher', 0.26361622403968255)]\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The results show that for example the main problem resides that German contains 4 types of superlatives (Put reference here... German grammar) for example in the case of *gross* although not exactly it indeed returned a form of the superlative (in the adjective form) however we were intially testing for the adverbial form \"am\".\n",
      "\n",
      "Basically German construct superlative  differently for adverbs and for adjetives and the for adjetives they are also declined:\n",
      "For *tief*  (deep)\n",
      "\n",
      "\n",
      "Positive | Comparative | Superlative\n",
      "--- | --- | ---\n",
      "tief | tiefer | (der/das/die) tiefste\n",
      "\n",
      "\n",
      "Comparative and superlative form decline the same way as any adjective when used before a noun with the same weak and strong endings:\n",
      "\n",
      "\"ein schnellerer Zug der schenellste Zug, in der tiefsten Schlucht der Erde\" (* look for other samples*) thus, creating even more variation whereas in english only a word was used for all the same purpose.\n",
      "\n",
      "\n",
      "For the superlative of adverbs a phrase is used formed using tjhe stemm in *-st* wutg tge ending *-en*, togheter with *a*.  *Schumacher f\u00e4hrt am schnellsten*. At the begininng of this adverbial case was used for translation however, after testing  can be seen when interpreted as superlative of adverbs the model performs worst giving a accuracy of **0.80 %  (7 / 870)**\n",
      "\n",
      "However what is clear is that the model itself model the relationships of the different declinations of an adjective/adverb for example\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pp.pprint ( model.cosine('beste') )\n",
      "pp.pprint ( model.cosine('kaeltesten') )\n",
      "pp.pprint ( model.cosine('groessten') )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'beste': [('bester', 0.80862715211137748),\n",
        "           ('bestes', 0.78943320248449433),\n",
        "           ('nebendarstellerin', 0.75782492147869929),\n",
        "           ('nominierung', 0.75595610309258698),\n",
        "           ('newcomerin', 0.75250601981011456),\n",
        "           ('nominierungen', 0.74955782266301774),\n",
        "           ('besten', 0.74561018058208761),\n",
        "           ('nominiert', 0.74412707212303697),\n",
        "           ('nachwuchsdarstellerin', 0.74389365816426301),\n",
        "           ('hauptdarstellerin', 0.73982425496171822)]}\n",
        "{"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'kaeltesten': [('kaelteste', 0.91810972087759257),\n",
        "                ('waermste', 0.90163202875639015),\n",
        "                ('waermsten', 0.89932468079579042),\n",
        "                ('tageshoechsttemperaturen', 0.88498595735424079),\n",
        "                ('tiefsttemperatur', 0.88352721493881337),\n",
        "                ('kaeltester', 0.88350750285391344),\n",
        "                ('hoechsttemperatur', 0.88262475124060236),\n",
        "                ('tiefsttemperaturen', 0.88091755415863826),\n",
        "                ('hoechsttemperaturen', 0.8733385190839853),\n",
        "                ('niederschlagsreichste', 0.870620500053778)]}\n",
        "{"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'groessten': [('groesste', 0.85921650586401255),\n",
        "               ('zweitgroesste', 0.75420790558277784),\n",
        "               ('groesster', 0.75380146788503666),\n",
        "               ('groessere', 0.73994229143262991),\n",
        "               ('grossteil', 0.73698127336012864),\n",
        "               ('viertgroesste', 0.73181306637694488),\n",
        "               ('schweizweit', 0.72399316123828994),\n",
        "               ('drittgroesste', 0.72018221257676318),\n",
        "               ('zentralschweiz', 0.69883588240525507),\n",
        "               ('groesstenteils', 0.69482223924991704)]}\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can notice that if instead of comparing with the closest matches we use the 3 first we can get an increase in this taks of  **put the increase here**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Present Participle"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets take a look on the present participle taks which alos gives us **3.04 %  (23 / 756)** and for some reason the model fails to output a valid value.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# vec[1] - vec[0] + vec[2] = vec[3]\n",
      "\n",
      "par = ['tanzen', 'tanzend', 'entdecken', 'entdeckend']\n",
      "pp.pprint(model.analogy(pos=[par[1], par[2]], neg=[par[0]], n=5))\n",
      "pp.pprint ( model.cosine('beschreibend') )\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('geisterhafte', 0.26418601337670883),\n",
        " ('hinabsteigt', 0.25551062172785172),\n",
        " ('raetselhaftes', 0.25456932425170997),\n",
        " ('marsbewohner', 0.25403336110744312),\n",
        " ('uebersaete', 0.25398876264083414),\n",
        " ('schattenhafte', 0.25322558342327617)]\n",
        "{"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'beschreibend': [('verwendungszusammenhang', 0.83684823742129311),\n",
        "                  ('vorfindliche', 0.83471254073863654),\n",
        "                  ('alltagssprachliche', 0.83397479828428067),\n",
        "                  ('definitionsversuche', 0.8303264163581433),\n",
        "                  ('alltagssprachlichen', 0.83017055933111883),\n",
        "                  ('sprachwissenschaftlichem', 0.82948779367706937),\n",
        "                  ('selbstreferentialitaet', 0.82909718551769196),\n",
        "                  ('wahrheitsfaehig', 0.82563164565528124),\n",
        "                  ('wortverwendungen', 0.82526056164860639),\n",
        "                  ('bewertend', 0.82481696655952264)]}\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Capital City \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes more of one answer is valid, however as we are limited to one then we get a negative result for example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q = [\"berlin\", \"deutschland\", \"london\", \"england\"]\n",
      "model.analogy(pos=[q[1],q[2]],neg=[q[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "[('britannien', 0.28691692890875858),\n",
        " ('england', 0.27996419067077083),\n",
        " ('usa', 0.26159823903397261),\n",
        " ('aylesbury', 0.25349568249575793),\n",
        " ('maidstone', 0.2512002459575608),\n",
        " ('littlehampton', 0.24938050764181516),\n",
        " ('sidcup', 0.24846604189666219),\n",
        " ('vereinigtes', 0.24839421921531202),\n",
        " ('nordengland', 0.24834029966479196),\n",
        " ('ulverston', 0.24803733037950496)]"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Nationality"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# vec[1] - vec[0] + vec[2] = vec[3]\n",
      "\n",
      "nal = ['norwegen', 'norwegisch', 'spanien', 'spanisch']\n",
      "pp.pprint(model.analogy(pos=[nal[1], nal[2]], neg=[nal[0]], n=5))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('spanisch', 0.25843116357810375),\n",
        " ('katalanisch', 0.25462608984656315),\n",
        " ('spanischen', 0.24571794856629298),\n",
        " ('baskisch', 0.23393161608951638),\n",
        " ('galicisch', 0.2322161226898031),\n",
        " ('spanische', 0.22902151780836427)]\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}